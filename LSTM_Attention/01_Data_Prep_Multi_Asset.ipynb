{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在拉取数据: NVDA\n",
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVDA 数据已保存\n",
      "正在拉取数据: AAPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL 数据已保存\n",
      "正在拉取数据: MSFT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSFT 数据已保存\n",
      "正在拉取数据: AMZN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMZN 数据已保存\n",
      "正在拉取数据: GOOG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOG 数据已保存\n",
      "正在拉取数据: META\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "META 数据已保存\n",
      "正在拉取数据: JPM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPM 数据已保存\n",
      "正在拉取数据: GS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GS 数据已保存\n",
      "正在拉取数据: BAC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAC 数据已保存\n",
      "正在拉取数据: WFC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WFC 数据已保存\n",
      "正在拉取数据: XOM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOM 数据已保存\n",
      "正在拉取数据: CVX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVX 数据已保存\n",
      "正在拉取数据: BP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP 数据已保存\n",
      "正在拉取数据: TSLA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA 数据已保存\n",
      "正在拉取数据: KO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KO 数据已保存\n",
      "正在拉取数据: MCD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCD 数据已保存\n",
      "正在拉取数据: PG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PG 数据已保存\n",
      "正在拉取数据: PEP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEP 数据已保存\n",
      "正在拉取数据: JNJ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JNJ 数据已保存\n",
      "正在拉取数据: PFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PFE 数据已保存\n",
      "正在拉取数据: UNH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNH 数据已保存\n",
      "正在拉取数据: BA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BA 数据已保存\n",
      "正在拉取数据: CAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT 数据已保存\n",
      "正在拉取数据: GE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GE 数据已保存\n",
      "正在拉取数据: NEE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEE 数据已保存\n",
      "正在拉取数据: DUK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUK 数据已保存\n",
      "正在拉取数据: T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T 数据已保存\n",
      "正在拉取数据: VZ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VZ 数据已保存\n",
      "正在拉取数据: HD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HD 数据已保存\n",
      "正在拉取数据: WMT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMT 数据已保存\n",
      "正在拉取数据: LIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIN 数据已保存\n",
      "正在拉取数据: BHP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BHP 数据已保存\n",
      "正在拉取数据: QQQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QQQ 数据已保存\n",
      "正在拉取数据: SPY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY 数据已保存\n",
      "所有股票数据已成功保存。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import os\n",
    "\n",
    "# 设定存储路径\n",
    "directory = \"32_Pool\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# 32只股票+ETF的ticker列表\n",
    "tickers = [\"NVDA\", \"AAPL\", \"MSFT\", \"AMZN\", \"GOOG\", \"META\",\n",
    "           \"JPM\", \"GS\", \"BAC\", \"WFC\",\n",
    "           \"XOM\", \"CVX\", \"BP\",\n",
    "           \"TSLA\", \"KO\", \"MCD\", \"PG\", \"PEP\",\n",
    "           \"JNJ\", \"PFE\", \"UNH\",\n",
    "           \"BA\", \"CAT\", \"GE\",\n",
    "           \"NEE\", \"DUK\",\n",
    "           \"T\", \"VZ\",\n",
    "           \"HD\", \"WMT\",\n",
    "           \"LIN\", \"BHP\",\n",
    "           \"QQQ\", \"SPY\"]\n",
    "\n",
    "# 拉取股票数据并保存为CSV\n",
    "for ticker in tickers:\n",
    "    print(f\"正在拉取数据: {ticker}\")\n",
    "    stock_data = yf.download(ticker, start=\"2010-01-01\", end=\"2020-12-31\")\n",
    "    \n",
    "    # 只保留需要的列（Open, High, Low, Close, Volume）\n",
    "    stock_data = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "    \n",
    "    # 将数据保存为CSV\n",
    "    stock_data.to_csv(f\"{directory}/{ticker}_data.csv\")\n",
    "    print(f\"{ticker} 数据已保存\")\n",
    "\n",
    "print(\"所有股票数据已成功保存。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完毕: BP_data.csv\n",
      "处理完毕: MSFT_data.csv\n",
      "处理完毕: CVX_data.csv\n",
      "处理完毕: PEP_data.csv\n",
      "处理完毕: VZ_data.csv\n",
      "处理完毕: MCD_data.csv\n",
      "处理完毕: HD_data.csv\n",
      "处理完毕: XOM_data.csv\n",
      "处理完毕: BA_data.csv\n",
      "处理完毕: TSLA_data.csv\n",
      "处理完毕: QQQ_data.csv\n",
      "处理完毕: NEE_data.csv\n",
      "处理完毕: DUK_data.csv\n",
      "处理完毕: META_data.csv\n",
      "处理完毕: AMZN_data.csv\n",
      "处理完毕: GOOG_data.csv\n",
      "处理完毕: JNJ_data.csv\n",
      "处理完毕: PFE_data.csv\n",
      "处理完毕: BHP_data.csv\n",
      "处理完毕: KO_data.csv\n",
      "处理完毕: LIN_data.csv\n",
      "处理完毕: JPM_data.csv\n",
      "处理完毕: PG_data.csv\n",
      "处理完毕: T_data.csv\n",
      "处理完毕: GS_data.csv\n",
      "处理完毕: WMT_data.csv\n",
      "处理完毕: SPY_data.csv\n",
      "处理完毕: CAT_data.csv\n",
      "处理完毕: NVDA_data.csv\n",
      "处理完毕: GE_data.csv\n",
      "处理完毕: UNH_data.csv\n",
      "处理完毕: BAC_data.csv\n",
      "处理完毕: AAPL_data.csv\n",
      "处理完毕: WFC_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 设定存储路径\n",
    "directory = \"32_Pool\"\n",
    "\n",
    "# 处理每个CSV文件\n",
    "for ticker in os.listdir(directory):\n",
    "    if ticker.endswith(\"_data.csv\"):\n",
    "        file_path = os.path.join(directory, ticker)\n",
    "        \n",
    "        # 读取CSV文件\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # 删除第二行和第三行\n",
    "        df = df.drop([0, 1])\n",
    "\n",
    "        # 重置索引\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # 将第一行的第一列名称改为 'Date'\n",
    "        df.columns.values[0] = 'Date'\n",
    "\n",
    "        # 保存修改后的文件\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "        print(f\"处理完毕: {ticker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TSLA', 'AAPL', 'GE', 'QQQ', 'NVDA', 'UNH', 'CAT', 'AMZN', 'NEE', 'HD']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 设定存储路径\n",
    "directory = \"32_Pool\"\n",
    "tickers = [\"NVDA\", \"AAPL\", \"MSFT\", \"AMZN\", \"GOOG\", \"META\",\n",
    "           \"JPM\", \"GS\", \"BAC\", \"WFC\",\n",
    "           \"XOM\", \"CVX\", \"BP\",\n",
    "           \"TSLA\", \"KO\", \"MCD\", \"PG\", \"PEP\",\n",
    "           \"JNJ\", \"PFE\", \"UNH\",\n",
    "           \"BA\", \"CAT\", \"GE\",\n",
    "           \"NEE\", \"DUK\",\n",
    "           \"T\", \"VZ\",\n",
    "           \"HD\", \"WMT\",\n",
    "           \"LIN\", \"BHP\",\n",
    "           \"QQQ\", \"SPY\"]\n",
    "\n",
    "# 定义计算收益率、夏普率、波动率的函数\n",
    "def calculate_metrics(data, n=100, risk_free_rate=0.02):\n",
    "    \"\"\"\n",
    "    计算收益率、夏普率和波动率\n",
    "    - n: 收益计算周期（100 天）\n",
    "    - risk_free_rate: 无风险利率，假设 2%\n",
    "    \"\"\"\n",
    "    # 计算收益率（过去 n 天的累计收益率）\n",
    "    data['Return'] = data['Close'].pct_change()\n",
    "    rolling_return = data['Close'].pct_change(n).iloc[-1]\n",
    "    \n",
    "    # 计算波动率（标准差）\n",
    "    volatility = data['Return'].rolling(n).std().iloc[-1]\n",
    "    \n",
    "    # 计算夏普率（超额收益 / 波动率）\n",
    "    excess_return = data['Return'].mean() * 252 - risk_free_rate\n",
    "    sharpe_ratio = excess_return / (data['Return'].std() * np.sqrt(252)) if volatility != 0 else 0\n",
    "\n",
    "    return rolling_return, sharpe_ratio, volatility\n",
    "\n",
    "# 计算每只股票的评分\n",
    "scores = {}\n",
    "for ticker in tickers:\n",
    "    file_path = os.path.join(directory, f\"{ticker}_data.csv\")\n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n",
    "        \n",
    "        # 计算指标\n",
    "        return_100, sharpe, vol = calculate_metrics(data, n=100)\n",
    "        \n",
    "        # 计算最终评分\n",
    "        score = 0.5 * return_100 + 0.3 * sharpe - 0.2 * vol\n",
    "        scores[ticker] = score\n",
    "\n",
    "# 选择得分最高的 10 只股票\n",
    "top_10_stocks = sorted(scores, key=scores.get, reverse=True)[:10]\n",
    "top_10_stocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有数据已成功保存到 combined_10_stocks_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 设定存储路径\n",
    "directory = \"32_Pool\"\n",
    "output_file = \"combined_10_stocks_data.csv\"\n",
    "\n",
    "# 10 只股票\n",
    "tickers = ['TSLA', 'AAPL', 'GE', 'QQQ', 'NVDA', 'UNH', 'CAT', 'AMZN', 'NEE', 'HD']\n",
    "\n",
    "# 计算 RSI\n",
    "def compute_rsi(data, window):\n",
    "    delta = data.diff(1)\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "# 初始化 DataFrame\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# 遍历 10 只股票\n",
    "for ticker in tickers:\n",
    "    file_path = os.path.join(directory, f\"{ticker}_data.csv\")\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"文件 {file_path} 不存在，跳过 {ticker}\")\n",
    "        continue\n",
    "\n",
    "    # 加载数据\n",
    "    stock_data = pd.read_csv(file_path, index_col=\"Date\", parse_dates=True)\n",
    "\n",
    "    # 计算 RSI（7天 & 14天）\n",
    "    stock_data[f'{ticker}_RSI_7'] = compute_rsi(stock_data['Close'], 7)\n",
    "    stock_data[f'{ticker}_RSI_14'] = compute_rsi(stock_data['Close'], 14)\n",
    "\n",
    "    # 计算 MACD\n",
    "    short_ema = stock_data['Close'].ewm(span=12, adjust=False).mean()\n",
    "    long_ema = stock_data['Close'].ewm(span=26, adjust=False).mean()\n",
    "    stock_data[f'{ticker}_MACD'] = short_ema - long_ema\n",
    "    stock_data[f'{ticker}_MACD_Signal'] = stock_data[f'{ticker}_MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    # 选取所需列，并重命名\n",
    "    stock_data = stock_data.rename(columns={\n",
    "        'Open': f'{ticker}_Open',\n",
    "        'High': f'{ticker}_High',\n",
    "        'Low': f'{ticker}_Low',\n",
    "        'Close': f'{ticker}_Close',\n",
    "        'Volume': f'{ticker}_Volume'\n",
    "    })\n",
    "    \n",
    "    selected_columns = [f'{ticker}_Open', f'{ticker}_High', f'{ticker}_Low', f'{ticker}_Close', f'{ticker}_Volume', \n",
    "                        f'{ticker}_RSI_7', f'{ticker}_RSI_14', f'{ticker}_MACD', f'{ticker}_MACD_Signal']\n",
    "\n",
    "    # 合并数据\n",
    "    if combined_data.empty:\n",
    "        combined_data = stock_data[selected_columns]\n",
    "    else:\n",
    "        combined_data = pd.concat([combined_data, stock_data[selected_columns]], axis=1)\n",
    "\n",
    "# **添加日期转换**\n",
    "combined_data.reset_index(inplace=True)  # 把 Date 从索引变成普通列\n",
    "combined_data[\"Days_Since_Start\"] = (combined_data[\"Date\"] - combined_data[\"Date\"].min()).dt.days  # 计算天数\n",
    "combined_data.drop(columns=[\"Date\"], inplace=True)  # 删除原始日期列\n",
    "\n",
    "# **调整列顺序，把 Days_Since_Start 放在第一列**\n",
    "columns_order = [\"Days_Since_Start\"] + [col for col in combined_data.columns if col != \"Days_Since_Start\"]\n",
    "combined_data = combined_data[columns_order]\n",
    "\n",
    "# 去掉 NaN 行\n",
    "combined_data.dropna(inplace=True)\n",
    "\n",
    "# 保存到 CSV\n",
    "combined_data.to_csv(output_file, index=False)\n",
    "print(f\"所有数据已成功保存到 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days_Since_Start</th>\n",
       "      <th>TSLA_Open</th>\n",
       "      <th>TSLA_High</th>\n",
       "      <th>TSLA_Low</th>\n",
       "      <th>TSLA_Close</th>\n",
       "      <th>TSLA_Volume</th>\n",
       "      <th>TSLA_RSI_7</th>\n",
       "      <th>TSLA_RSI_14</th>\n",
       "      <th>TSLA_MACD</th>\n",
       "      <th>TSLA_MACD_Signal</th>\n",
       "      <th>...</th>\n",
       "      <th>NEE_MACD_Signal</th>\n",
       "      <th>HD_Open</th>\n",
       "      <th>HD_High</th>\n",
       "      <th>HD_Low</th>\n",
       "      <th>HD_Close</th>\n",
       "      <th>HD_Volume</th>\n",
       "      <th>HD_RSI_7</th>\n",
       "      <th>HD_RSI_14</th>\n",
       "      <th>HD_MACD</th>\n",
       "      <th>HD_MACD_Signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>1.424667</td>\n",
       "      <td>1.483333</td>\n",
       "      <td>1.394667</td>\n",
       "      <td>1.460667</td>\n",
       "      <td>37297500.0</td>\n",
       "      <td>92.220196</td>\n",
       "      <td>43.408794</td>\n",
       "      <td>-0.064685</td>\n",
       "      <td>-0.083391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059857</td>\n",
       "      <td>19.278965</td>\n",
       "      <td>19.349948</td>\n",
       "      <td>19.058918</td>\n",
       "      <td>19.215080</td>\n",
       "      <td>17061600</td>\n",
       "      <td>25.229445</td>\n",
       "      <td>25.954283</td>\n",
       "      <td>-0.802271</td>\n",
       "      <td>-0.824908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197</td>\n",
       "      <td>1.456667</td>\n",
       "      <td>1.456667</td>\n",
       "      <td>1.336667</td>\n",
       "      <td>1.353333</td>\n",
       "      <td>27379500.0</td>\n",
       "      <td>71.260949</td>\n",
       "      <td>39.206237</td>\n",
       "      <td>-0.058209</td>\n",
       "      <td>-0.078355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071355</td>\n",
       "      <td>18.987938</td>\n",
       "      <td>19.896520</td>\n",
       "      <td>18.895661</td>\n",
       "      <td>19.825537</td>\n",
       "      <td>23279400</td>\n",
       "      <td>44.368562</td>\n",
       "      <td>43.190715</td>\n",
       "      <td>-0.756203</td>\n",
       "      <td>-0.811167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198</td>\n",
       "      <td>1.377333</td>\n",
       "      <td>1.393333</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.348000</td>\n",
       "      <td>18787500.0</td>\n",
       "      <td>74.198423</td>\n",
       "      <td>39.159154</td>\n",
       "      <td>-0.052897</td>\n",
       "      <td>-0.073263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079636</td>\n",
       "      <td>19.719066</td>\n",
       "      <td>19.882326</td>\n",
       "      <td>19.413839</td>\n",
       "      <td>19.499018</td>\n",
       "      <td>17161300</td>\n",
       "      <td>37.425292</td>\n",
       "      <td>44.047680</td>\n",
       "      <td>-0.737539</td>\n",
       "      <td>-0.796441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>1.358000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>14367000.0</td>\n",
       "      <td>72.916658</td>\n",
       "      <td>46.915168</td>\n",
       "      <td>-0.043984</td>\n",
       "      <td>-0.067407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087182</td>\n",
       "      <td>19.669378</td>\n",
       "      <td>20.208849</td>\n",
       "      <td>19.669378</td>\n",
       "      <td>20.031391</td>\n",
       "      <td>26142700</td>\n",
       "      <td>44.414890</td>\n",
       "      <td>52.659520</td>\n",
       "      <td>-0.672043</td>\n",
       "      <td>-0.771562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>1.412667</td>\n",
       "      <td>1.437333</td>\n",
       "      <td>1.404000</td>\n",
       "      <td>1.419333</td>\n",
       "      <td>9804000.0</td>\n",
       "      <td>65.010249</td>\n",
       "      <td>57.983173</td>\n",
       "      <td>-0.034957</td>\n",
       "      <td>-0.060917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093594</td>\n",
       "      <td>19.974605</td>\n",
       "      <td>20.130768</td>\n",
       "      <td>19.804246</td>\n",
       "      <td>20.052687</td>\n",
       "      <td>18979200</td>\n",
       "      <td>49.562788</td>\n",
       "      <td>54.446405</td>\n",
       "      <td>-0.611372</td>\n",
       "      <td>-0.739524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Days_Since_Start  TSLA_Open  TSLA_High  TSLA_Low  TSLA_Close  TSLA_Volume  \\\n",
       "0               196   1.424667   1.483333  1.394667    1.460667   37297500.0   \n",
       "1               197   1.456667   1.456667  1.336667    1.353333   27379500.0   \n",
       "2               198   1.377333   1.393333  1.300000    1.348000   18787500.0   \n",
       "3               199   1.366667   1.416667  1.358000    1.400000   14367000.0   \n",
       "4               200   1.412667   1.437333  1.404000    1.419333    9804000.0   \n",
       "\n",
       "   TSLA_RSI_7  TSLA_RSI_14  TSLA_MACD  TSLA_MACD_Signal  ...  NEE_MACD_Signal  \\\n",
       "0   92.220196    43.408794  -0.064685         -0.083391  ...         0.059857   \n",
       "1   71.260949    39.206237  -0.058209         -0.078355  ...         0.071355   \n",
       "2   74.198423    39.159154  -0.052897         -0.073263  ...         0.079636   \n",
       "3   72.916658    46.915168  -0.043984         -0.067407  ...         0.087182   \n",
       "4   65.010249    57.983173  -0.034957         -0.060917  ...         0.093594   \n",
       "\n",
       "     HD_Open    HD_High     HD_Low   HD_Close  HD_Volume   HD_RSI_7  \\\n",
       "0  19.278965  19.349948  19.058918  19.215080   17061600  25.229445   \n",
       "1  18.987938  19.896520  18.895661  19.825537   23279400  44.368562   \n",
       "2  19.719066  19.882326  19.413839  19.499018   17161300  37.425292   \n",
       "3  19.669378  20.208849  19.669378  20.031391   26142700  44.414890   \n",
       "4  19.974605  20.130768  19.804246  20.052687   18979200  49.562788   \n",
       "\n",
       "   HD_RSI_14   HD_MACD  HD_MACD_Signal  \n",
       "0  25.954283 -0.802271       -0.824908  \n",
       "1  43.190715 -0.756203       -0.811167  \n",
       "2  44.047680 -0.737539       -0.796441  \n",
       "3  52.659520 -0.672043       -0.771562  \n",
       "4  54.446405 -0.611372       -0.739524  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/home/jesse/Projects/RL_Testing/LSTM_Attention/combined_10_stocks_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在拉取数据: TSLA\n",
      "TSLA 数据已保存\n",
      "正在拉取数据: AAPL\n",
      "AAPL 数据已保存\n",
      "正在拉取数据: GE\n",
      "GE 数据已保存\n",
      "正在拉取数据: QQQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QQQ 数据已保存\n",
      "正在拉取数据: NVDA\n",
      "NVDA 数据已保存\n",
      "正在拉取数据: UNH\n",
      "UNH 数据已保存\n",
      "正在拉取数据: CAT\n",
      "CAT 数据已保存\n",
      "正在拉取数据: AMZN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMZN 数据已保存\n",
      "正在拉取数据: NEE\n",
      "NEE 数据已保存\n",
      "正在拉取数据: HD\n",
      "HD 数据已保存\n",
      "所有股票数据已成功保存。\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import os\n",
    "\n",
    "# 设定存储路径\n",
    "directory = \"10_Pool_Test\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# 10 只股票\n",
    "tickers = ['TSLA', 'AAPL', 'GE', 'QQQ', 'NVDA', 'UNH', 'CAT', 'AMZN', 'NEE', 'HD']\n",
    "\n",
    "# 拉取股票数据并保存为CSV\n",
    "for ticker in tickers:\n",
    "    print(f\"正在拉取数据: {ticker}\")\n",
    "    stock_data = yf.download(ticker, start=\"2021-01-01\", end=\"2024-12-31\")\n",
    "    \n",
    "    # 只保留需要的列（Open, High, Low, Close, Volume）\n",
    "    stock_data = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "    \n",
    "    # 将数据保存为CSV\n",
    "    stock_data.to_csv(f\"{directory}/{ticker}_data.csv\")\n",
    "    print(f\"{ticker} 数据已保存\")\n",
    "\n",
    "print(\"所有股票数据已成功保存。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完毕: HD_data.csv\n",
      "处理完毕: TSLA_data.csv\n",
      "处理完毕: QQQ_data.csv\n",
      "处理完毕: NEE_data.csv\n",
      "处理完毕: AMZN_data.csv\n",
      "处理完毕: CAT_data.csv\n",
      "处理完毕: NVDA_data.csv\n",
      "处理完毕: GE_data.csv\n",
      "处理完毕: UNH_data.csv\n",
      "处理完毕: AAPL_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 设定存储路径\n",
    "directory = \"10_Pool_Test\"\n",
    "\n",
    "# 处理每个CSV文件\n",
    "for ticker in os.listdir(directory):\n",
    "    if ticker.endswith(\"_data.csv\"):\n",
    "        file_path = os.path.join(directory, ticker)\n",
    "        \n",
    "        # 读取CSV文件\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # 删除第二行和第三行\n",
    "        df = df.drop([0, 1])\n",
    "\n",
    "        # 重置索引\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # 将第一行的第一列名称改为 'Date'\n",
    "        df.columns.values[0] = 'Date'\n",
    "\n",
    "        # 保存修改后的文件\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "        print(f\"处理完毕: {ticker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有数据已成功保存到 combined_10_stocks_data_test.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 设定存储路径\n",
    "directory = \"10_Pool_Test\"\n",
    "output_file = \"combined_10_stocks_data_test.csv\"\n",
    "\n",
    "# 10 只股票\n",
    "tickers = ['TSLA', 'AAPL', 'GE', 'QQQ', 'NVDA', 'UNH', 'CAT', 'AMZN', 'NEE', 'HD']\n",
    "\n",
    "# 计算 RSI\n",
    "def compute_rsi(data, window):\n",
    "    delta = data.diff(1)\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "# 初始化 DataFrame\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# 遍历 10 只股票\n",
    "for ticker in tickers:\n",
    "    file_path = os.path.join(directory, f\"{ticker}_data.csv\")\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"文件 {file_path} 不存在，跳过 {ticker}\")\n",
    "        continue\n",
    "\n",
    "    # 加载数据\n",
    "    stock_data = pd.read_csv(file_path, index_col=\"Date\", parse_dates=True)\n",
    "\n",
    "    # 计算 RSI（7天 & 14天）\n",
    "    stock_data[f'{ticker}_RSI_7'] = compute_rsi(stock_data['Close'], 7)\n",
    "    stock_data[f'{ticker}_RSI_14'] = compute_rsi(stock_data['Close'], 14)\n",
    "\n",
    "    # 计算 MACD\n",
    "    short_ema = stock_data['Close'].ewm(span=12, adjust=False).mean()\n",
    "    long_ema = stock_data['Close'].ewm(span=26, adjust=False).mean()\n",
    "    stock_data[f'{ticker}_MACD'] = short_ema - long_ema\n",
    "    stock_data[f'{ticker}_MACD_Signal'] = stock_data[f'{ticker}_MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    # 选取所需列，并重命名\n",
    "    stock_data = stock_data.rename(columns={\n",
    "        'Open': f'{ticker}_Open',\n",
    "        'High': f'{ticker}_High',\n",
    "        'Low': f'{ticker}_Low',\n",
    "        'Close': f'{ticker}_Close',\n",
    "        'Volume': f'{ticker}_Volume'\n",
    "    })\n",
    "    \n",
    "    selected_columns = [f'{ticker}_Open', f'{ticker}_High', f'{ticker}_Low', f'{ticker}_Close', f'{ticker}_Volume', \n",
    "                        f'{ticker}_RSI_7', f'{ticker}_RSI_14', f'{ticker}_MACD', f'{ticker}_MACD_Signal']\n",
    "\n",
    "    # 合并数据\n",
    "    if combined_data.empty:\n",
    "        combined_data = stock_data[selected_columns]\n",
    "    else:\n",
    "        combined_data = pd.concat([combined_data, stock_data[selected_columns]], axis=1)\n",
    "\n",
    "# **添加日期转换**\n",
    "combined_data.reset_index(inplace=True)  # 把 Date 从索引变成普通列\n",
    "combined_data[\"Days_Since_Start\"] = (combined_data[\"Date\"] - combined_data[\"Date\"].min()).dt.days  # 计算天数\n",
    "combined_data.drop(columns=[\"Date\"], inplace=True)  # 删除原始日期列\n",
    "\n",
    "# **调整列顺序，把 Days_Since_Start 放在第一列**\n",
    "columns_order = [\"Days_Since_Start\"] + [col for col in combined_data.columns if col != \"Days_Since_Start\"]\n",
    "combined_data = combined_data[columns_order]\n",
    "\n",
    "# 去掉 NaN 行\n",
    "combined_data.dropna(inplace=True)\n",
    "\n",
    "# 保存到 CSV\n",
    "combined_data.to_csv(output_file, index=False)\n",
    "print(f\"所有数据已成功保存到 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days_Since_Start</th>\n",
       "      <th>TSLA_Open</th>\n",
       "      <th>TSLA_High</th>\n",
       "      <th>TSLA_Low</th>\n",
       "      <th>TSLA_Close</th>\n",
       "      <th>TSLA_Volume</th>\n",
       "      <th>TSLA_RSI_7</th>\n",
       "      <th>TSLA_RSI_14</th>\n",
       "      <th>TSLA_MACD</th>\n",
       "      <th>TSLA_MACD_Signal</th>\n",
       "      <th>...</th>\n",
       "      <th>NEE_MACD_Signal</th>\n",
       "      <th>HD_Open</th>\n",
       "      <th>HD_High</th>\n",
       "      <th>HD_Low</th>\n",
       "      <th>HD_Close</th>\n",
       "      <th>HD_Volume</th>\n",
       "      <th>HD_RSI_7</th>\n",
       "      <th>HD_RSI_14</th>\n",
       "      <th>HD_MACD</th>\n",
       "      <th>HD_MACD_Signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>278.103333</td>\n",
       "      <td>282.666656</td>\n",
       "      <td>276.206665</td>\n",
       "      <td>282.213318</td>\n",
       "      <td>60199500</td>\n",
       "      <td>47.833454</td>\n",
       "      <td>68.150321</td>\n",
       "      <td>10.300506</td>\n",
       "      <td>8.958231</td>\n",
       "      <td>...</td>\n",
       "      <td>1.740426</td>\n",
       "      <td>253.401462</td>\n",
       "      <td>258.682529</td>\n",
       "      <td>252.140158</td>\n",
       "      <td>257.702545</td>\n",
       "      <td>4501900</td>\n",
       "      <td>63.479656</td>\n",
       "      <td>73.091011</td>\n",
       "      <td>3.430115</td>\n",
       "      <td>2.218191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>300.133331</td>\n",
       "      <td>279.606659</td>\n",
       "      <td>293.600006</td>\n",
       "      <td>123520200</td>\n",
       "      <td>64.065634</td>\n",
       "      <td>71.205519</td>\n",
       "      <td>10.982234</td>\n",
       "      <td>9.363032</td>\n",
       "      <td>...</td>\n",
       "      <td>1.887689</td>\n",
       "      <td>257.566528</td>\n",
       "      <td>259.308728</td>\n",
       "      <td>255.361544</td>\n",
       "      <td>258.682617</td>\n",
       "      <td>4025900</td>\n",
       "      <td>70.238550</td>\n",
       "      <td>73.743254</td>\n",
       "      <td>3.975167</td>\n",
       "      <td>2.569586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>297.126678</td>\n",
       "      <td>298.633331</td>\n",
       "      <td>290.533325</td>\n",
       "      <td>294.363342</td>\n",
       "      <td>69394800</td>\n",
       "      <td>71.969095</td>\n",
       "      <td>70.956772</td>\n",
       "      <td>11.452091</td>\n",
       "      <td>9.780844</td>\n",
       "      <td>...</td>\n",
       "      <td>2.011335</td>\n",
       "      <td>258.991043</td>\n",
       "      <td>259.199728</td>\n",
       "      <td>255.615502</td>\n",
       "      <td>256.432159</td>\n",
       "      <td>2472200</td>\n",
       "      <td>79.683218</td>\n",
       "      <td>68.425593</td>\n",
       "      <td>4.177377</td>\n",
       "      <td>2.891144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>290.116669</td>\n",
       "      <td>297.166656</td>\n",
       "      <td>286.220001</td>\n",
       "      <td>288.053345</td>\n",
       "      <td>82002000</td>\n",
       "      <td>71.894458</td>\n",
       "      <td>65.404988</td>\n",
       "      <td>11.186343</td>\n",
       "      <td>10.061944</td>\n",
       "      <td>...</td>\n",
       "      <td>2.036145</td>\n",
       "      <td>254.063883</td>\n",
       "      <td>254.807961</td>\n",
       "      <td>247.793722</td>\n",
       "      <td>248.673904</td>\n",
       "      <td>4337000</td>\n",
       "      <td>46.958915</td>\n",
       "      <td>56.237920</td>\n",
       "      <td>3.669306</td>\n",
       "      <td>3.046777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>273.333344</td>\n",
       "      <td>282.666656</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>278.476654</td>\n",
       "      <td>79134000</td>\n",
       "      <td>45.304772</td>\n",
       "      <td>53.031668</td>\n",
       "      <td>10.086704</td>\n",
       "      <td>10.066896</td>\n",
       "      <td>...</td>\n",
       "      <td>2.025929</td>\n",
       "      <td>250.597648</td>\n",
       "      <td>256.758898</td>\n",
       "      <td>249.472448</td>\n",
       "      <td>252.303543</td>\n",
       "      <td>3463000</td>\n",
       "      <td>59.026771</td>\n",
       "      <td>60.790691</td>\n",
       "      <td>3.518973</td>\n",
       "      <td>3.141216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Days_Since_Start   TSLA_Open   TSLA_High    TSLA_Low  TSLA_Close  \\\n",
       "0                18  278.103333  282.666656  276.206665  282.213318   \n",
       "1                21  285.000000  300.133331  279.606659  293.600006   \n",
       "2                22  297.126678  298.633331  290.533325  294.363342   \n",
       "3                23  290.116669  297.166656  286.220001  288.053345   \n",
       "4                24  273.333344  282.666656  267.000000  278.476654   \n",
       "\n",
       "   TSLA_Volume  TSLA_RSI_7  TSLA_RSI_14  TSLA_MACD  TSLA_MACD_Signal  ...  \\\n",
       "0     60199500   47.833454    68.150321  10.300506          8.958231  ...   \n",
       "1    123520200   64.065634    71.205519  10.982234          9.363032  ...   \n",
       "2     69394800   71.969095    70.956772  11.452091          9.780844  ...   \n",
       "3     82002000   71.894458    65.404988  11.186343         10.061944  ...   \n",
       "4     79134000   45.304772    53.031668  10.086704         10.066896  ...   \n",
       "\n",
       "   NEE_MACD_Signal     HD_Open     HD_High      HD_Low    HD_Close  HD_Volume  \\\n",
       "0         1.740426  253.401462  258.682529  252.140158  257.702545    4501900   \n",
       "1         1.887689  257.566528  259.308728  255.361544  258.682617    4025900   \n",
       "2         2.011335  258.991043  259.199728  255.615502  256.432159    2472200   \n",
       "3         2.036145  254.063883  254.807961  247.793722  248.673904    4337000   \n",
       "4         2.025929  250.597648  256.758898  249.472448  252.303543    3463000   \n",
       "\n",
       "    HD_RSI_7  HD_RSI_14   HD_MACD  HD_MACD_Signal  \n",
       "0  63.479656  73.091011  3.430115        2.218191  \n",
       "1  70.238550  73.743254  3.975167        2.569586  \n",
       "2  79.683218  68.425593  4.177377        2.891144  \n",
       "3  46.958915  56.237920  3.669306        3.046777  \n",
       "4  59.026771  60.790691  3.518973        3.141216  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/home/jesse/Projects/RL_Testing/LSTM_Attention/combined_10_stocks_data_test.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 共有 991 行, 91 列\n"
     ]
    }
   ],
   "source": [
    "rows, cols = df.shape\n",
    "print(f\"DataFrame 共有 {rows} 行, {cols} 列\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
